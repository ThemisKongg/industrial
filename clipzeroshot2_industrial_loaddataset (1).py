# -*- coding: utf-8 -*-
"""clipZeroshot2_Industrial_loaddataset.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lgqPzrJpfW1bfgcC1culrMiPZbyDqxCS
"""

import torch
print("GPU:", torch.cuda.get_device_name(0) if torch.cuda.is_available() else "NO GPU - Change Runtime Type to GPU!")

!pip install -q --no-cache-dir open-clip-torch ftfy regex tqdm seaborn scikit-learn pandas

"""https://drive.google.com/drive/folders/1GWxnvsydNkRWPO2xtJh8dIyg4CqQTpez?usp=sharing"""

from google.colab import drive
drive.mount('/content/drive')

import os

drive_root = "/content/drive/MyDrive/MVTec"
raw_dataset = f"{drive_root}/mvtec_anomaly_detection"
converted_dataset = f"{drive_root}/mvtec_imagefolder"

# Commented out IPython magic to ensure Python compatibility.
# Step 1: Mount Google Drive (highly recommended so you donâ€™t re-download every time)
from google.colab import drive
drive.mount('/content/drive')

# Step 2: Create a new folder in your Drive (or use /content if you prefer)
# %cd /content/drive/MyDrive   # or skip this line to stay in /content

# Create folder and go inside
!mkdir -p mvtec-anomaly-detection-full
# %cd mvtec-anomaly-detection-full

# Step 3: Clone the code repo (optional but clean)
!git clone https://github.com/raadon96/MVTec-Anomaly-Detection.git temp_code
!cp -r temp_code/* .   # copy all python files, notebooks, etc.
!rm -rf temp_code

# Step 4: Download the real ~5.3 GB dataset
!wget -q --show-progress https://www.mydrive.ch/shares/38536/3830184030e49fe74747669442f0f283/download/420938113-1629960298/mvtec_anomaly_detection.tar.xz
!tar -xf mvtec_anomaly_detection.tar.xz
!rm mvtec_anomaly_detection.tar.xz   # save space

# Step 5: Initialize Git + LFS
!git init
!git lfs install

# Track all image files (covers everything in MVTec)
!git lfs track "*.png" "*.jpg" "*.tif" "*.tiff" "*.bmp"

# Step 6: First commit
!git add .
!git commit -m "Add full MVTec Anomaly Detection dataset (5.3 GB) + code"

# Step 7: Create the repo on GitHub first!
#     â†’ Go to https://github.com/new
#     â†’ Name: mvtec-anomaly-detection-full (or whatever you like)
#     â†’ Do NOT add README/.gitignore (we already have files)
#     â†’ Create repository

# FINAL SAFE PUSH CELL â€” truly secure this time
from getpass import getpass

# This time it will prompt you and NOTHING will be saved in the notebook
PAT_TOKEN = getpass("Paste your NEW GitHub PAT here and press Enter â†’ ")

# Configure git
!git config --global user.name "ThemisKongg"
!git config --global user.email "themis725@gmail.com"

# Set remote with the token you just typed
!git remote set-url origin https://ThemisKongg:{PAT_TOKEN}@github.com/ThemisKongg/industrial.git

# Push (first time with force is fine)
!git branch -M main
!git push -u origin main --force

# =====================================================
# CLIP ZERO-SHOT ANOMALY DETECTION ON MVTec (WORKS NOW!)
# =====================================================

import torch
import open_clip
import os
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from tqdm.auto import tqdm
from PIL import Image
from torch.utils.data import Dataset, DataLoader
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import random
from pathlib import Path

# ------------------------------
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"Running on {device.upper()}")

# Load CLIP (same as before)
model, _, preprocess = open_clip.create_model_and_transforms('ViT-B-16', pretrained='laion400m_e31')
model.to(device).eval()
tokenizer = open_clip.get_tokenizer('ViT-B-16')

# ------------------------------
# Find MVTec folder (auto-detect common names)
possible_paths = ["/content/drive/MyDrive/mvtec_anomaly_detection"]
data_root = None
for p in possible_paths:
    if Path(p).exists():
        data_root = Path(p)
        break
if data_root is None:
    raise FileNotFoundError("MVTec folder not found! Check the path.")
print(f"Using dataset: {data_root}")

# ------------------------------
# Collect test images: normal ("good") vs anomalous
samples = []
categories = [p.name for p in data_root.iterdir() if p.is_dir()]

for cat in categories:
    test_dir = data_root / cat / "test"
    if not test_dir.exists():
        continue

    # Normal images
    for img_path in (test_dir / "good").glob("*.png"):
        samples.append((str(img_path), 0, cat))  # 0 = normal

    # Anomalous images (all defect types)
    for defect_type in test_dir.iterdir():
        if defect_type.is_dir() and defect_type.name != "good":
            for img_path in defect_type.glob("*.png"):
                samples.append((str(img_path), 1, cat))  # 1 = defective

print(f"Total test images found: {len(samples)}")
print(f"Normal: {sum(1 for x in samples if x[1]==0)} | Defective: {sum(1 for x in samples if x[1]==1)}")

# ------------------------------
# Optional: take a balanced subset (e.g. 500 normal + 500 defective)
normal = [s for s in samples if s[1] == 0]
defective = [s for s in samples if s[1] == 1]
test_samples = normal[:500] + defective[:500]
random.shuffle(test_samples)
print(f"Final test set: {len(test_samples)} images (balanced)")

# ------------------------------
# Dataset class
class MVTecDataset(Dataset):
    def __init__(self, samples):
        self.samples = samples
    def __len__(self):
        return len(self.samples)
    def __getitem__(self, idx):
        path, label, _ = self.samples[idx]
        img = Image.open(path).convert("RGB")
        return preprocess(img), torch.tensor(label, dtype=torch.long)

test_dataset = MVTecDataset(test_samples)
test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2, pin_memory=True)

# ------------------------------
# Zero-shot text prompts (very effective for industrial!)
prompts = [
    "a photo of a perfect {label} object.",
    "a high-quality industrial image of a {label} product.",
    "a defect-free {label} item on the production line.",
    "a flawless {label} with no scratches, cracks, or contamination.",
    "a normal {label} from quality control.",
]

classes = ["normal", "defective"]
text_inputs = []
for c in classes:
    texts = [p.format(label=c) for p in prompts]
    tokens = tokenizer(texts).to(device)
    with torch.no_grad():
        emb = model.encode_text(tokens)
        emb = emb.mean(dim=0)
        emb /= emb.norm()
    text_inputs.append(emb)

text_features = torch.stack(text_inputs).to(device)

# ------------------------------
# Inference
print("Running zero-shot inference on MVTec...")
all_preds = []
all_labels = []

with torch.no_grad():
    for imgs, labels in tqdm(test_loader, desc="Predicting"):
        imgs = imgs.to(device)
        img_features = model.encode_image(imgs)
        img_features /= img_features.norm(dim=-1, keepdim=True)

        similarity = (100.0 * img_features @ text_features.T).softmax(dim=-1)
        preds = similarity.argmax(dim=-1).cpu().numpy()

        all_preds.extend(preds)
        all_labels.extend(labels.numpy())

# ------------------------------
# Results
acc = accuracy_score(all_labels, all_preds)
print(f"\nZERO-SHOT CLIP ACCURACY ON MVTec: {acc*100:.2f}%")

# Confusion matrix
cm = confusion_matrix(all_labels, all_preds)
plt.figure(figsize=(6,5))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Predicted Normal', 'Predicted Defective'],
            yticklabels=['True Normal', 'True Defective'])
plt.title(f'CLIP Zero-Shot MVTec Anomaly Detection\nAccuracy: {acc*100:.2f}%')
plt.ylabel('True')
plt.xlabel('Predicted')
plt.tight_layout()
plt.show()

print("\nDetailed report:")
print(classification_report(all_labels, all_preds, target_names=['Normal', 'Defective'], digits=4))

# =============================================
# MVTec Object Classification - Zero-Shot CLIP (15 Classes)
# SAFELY EXCLUDE UNWANTED FOLDERS
# =============================================

from pathlib import Path

# Auto-detect MVTec folder
data_root = None
for p in ["/content/drive/MyDrive/mvtec_anomaly_detection"]:
    if Path(p).exists():
        data_root = Path(p)
        break
if data_root is None:
    raise FileNotFoundError("MVTec dataset folder not found! Please check the path.")

# Folders to completely ignore
exclude_folders = {
    '.git',
    'autoencoder',
    'mvtec-anomaly-detection-full',
    'processing',
    'results',
    'saved_models'
}

# Collect only the real 15 MVTec categories
raw_categories = [d for d in data_root.iterdir() if d.is_dir()]
classes = sorted([d.name for d in raw_categories if d.name not in exclude_folders])

print(f"Found {len(classes)} valid MVTec classes (excluded junk folders):")
print(classes)

# Collect test images from all valid categories
test_samples = []
label_map = {cls: idx for idx, cls in enumerate(classes)}

print("Collecting MVTec test images for object classification...")

for category in raw_categories:
    cat_name = category.name
    if cat_name in exclude_folders:
        print(f"Skipping excluded folder: {cat_name}")
        continue

    test_dir = category / "test"
    if not test_dir.exists():
        continue

    for subfolder in test_dir.iterdir():
        if subfolder.is_dir():
            for img_path in subfolder.glob("*.png"):
                test_samples.append((str(img_path), label_map[cat_name]))

print(f"Total test images collected: {len(test_samples)}")
random.shuffle(test_samples)

# Dataset class (unchanged)
class MVTecTestDataset(Dataset):
    def __init__(self, samples):
        self.samples = samples

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        path, label = self.samples[idx]
        try:
            img = Image.open(path).convert("RGB")
            return preprocess(img), torch.tensor(label, dtype=torch.long)
        except Exception as e:
            print(f"Error loading {path}: {e}")
            return preprocess(Image.new('RGB', (224, 224), color='black')), torch.tensor(0)

# Loader
test_dataset = MVTecTestDataset(test_samples)
test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2, pin_memory=True)

# Tailored prompts for object names
templates = [
    "a photo of a {}.",
    "a close-up photo of a {}.",
    "an industrial photo of a {}.",
    "a high-resolution image of a {}.",
    "a manufactured {}.",
    "a product image of a {}.",
    "a quality control photo of a {}.",
    "a frontal view of a {}.",
    "an image showing a {}."
]

# Build text features
print("Building object text classifier...")
text_features = []
with torch.no_grad():
    for c in classes:
        display_name = c.replace("_", " ")  # e.g., "metal nut"
        texts = [t.format(display_name) for t in templates]
        tokens = tokenizer(texts).to(device)
        emb = model.encode_text(tokens)
        emb /= emb.norm(dim=-1, keepdim=True)
        text_features.append(emb.mean(dim=0))
text_features = torch.stack(text_features)
text_features /= text_features.norm(dim=-1, keepdim=True)

# Zero-shot inference (unchanged)
print("Running inference on MVTec objects...")
all_preds, all_labels = [], []
with torch.no_grad():
    for imgs, labels in tqdm(test_loader, desc="Predicting"):
        imgs = imgs.to(device)
        img_feat = model.encode_image(imgs)
        img_feat /= img_feat.norm(dim=-1, keepdim=True)
        sim = (100.0 * img_feat @ text_features.T).softmax(dim=-1)
        pred = sim.argmax(dim=-1).cpu().numpy()
        all_preds.extend(pred)
        all_labels.extend(labels.numpy())

# Results
all_preds = np.array(all_preds)
all_labels = np.array(all_labels)
acc = accuracy_score(all_labels, all_preds)
print(f"\nðŸŽ‰ ZERO-SHOT ACCURACY: {acc*100:.2f}% (on clean MVTec 15 object/texture classes)")

# Confusion matrix
plt.figure(figsize=(12,10))
cm = confusion_matrix(all_labels, all_preds)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=classes, yticklabels=classes)
plt.title(f'CLIP Zero-Shot Object Classification on MVTec (15 Classes)\nAccuracy: {acc*100:.2f}%', fontsize=16)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

print("\nDetailed Report:")
print(classification_report(all_labels, all_preds, target_names=classes, digits=4))

import pandas as pd
from pathlib import Path

# Change this if your MVTec folder has a different name or location
data_root = Path("/content/drive/MyDrive/mvtec_anomaly_detection")  # Common alternatives: "./MVTec", "mvtec_anomaly_detection"

if not data_root.exists():
    raise FileNotFoundError(f"MVTec folder not found at {data_root}! Please check the path.")

# Folders to exclude (junk folders you mentioned)
exclude_folders = {
    '.git', 'autoencoder', 'mvtec-anomaly-detection-full',
    'processing', 'results', 'saved_models'
}

# Collect samples: only class label, from all test images (good + all defects)
samples = []

print("Generating CSV with only class labels from MVTec test set...")

for category in data_root.iterdir():
    if not category.is_dir():
        continue
    cat_name = category.name

    # Skip unwanted folders
    if cat_name in exclude_folders:
        print(f"Skipping excluded folder: {cat_name}")
        continue

    test_dir = category / "test"
    if not test_dir.exists():
        print(f"Skipping {cat_name} (no test folder)")
        continue

    # Go through all subfolders in test (good + all defect types)
    for subfolder in test_dir.iterdir():
        if subfolder.is_dir():
            for img_path in subfolder.glob("*.png"):
                # Use relative path for portability
                rel_path = img_path.relative_to(data_root.parent if data_root.parent != Path('.') else data_root)

                samples.append({
                    "filename": str(rel_path),
                    "class": cat_name
                })

# Create DataFrame
df = pd.DataFrame(samples)

# Save CSV
csv_filename = "mvtec_classes_only.csv"
df.to_csv(csv_filename, index=False)

print(f"\nDone! Generated {len(df)} rows (all test images).")
print(f"CSV saved as: {csv_filename}")
print(f"Classes included: {sorted(df['class'].unique())}")

print("\nFirst 10 rows preview:")
print(df.head(10))

print("\nClass distribution:")
print(df['class'].value_counts().sort_index())

from google.colab import files
files.download('mvtec_classes_only.csv')

